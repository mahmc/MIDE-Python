{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bdf57b0-dec0-4399-b614-feefa3f25ec3",
   "metadata": {},
   "source": [
    "# Apache Arrow\n",
    "\n",
    "<img src=\"images/apache_arrow.png\" alt=\"Drawing\" style=\"width: 750px;\"/> \n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/milocortes/diplomado_ciencia_datos_mide/blob/edicion-2024/notebooks/arrow_mide_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2920a8-9e8e-4317-94fd-55a2c6d01e1c",
   "metadata": {},
   "source": [
    "*  Apache Arrow (o Arrow por prevedad) es un proyecto open source de la Fundación Apache.\n",
    "*  Fue creado por Dremio y Wes McKinney, el creador de Pandas, y fue lanzado por primera vez en 2016.\n",
    "*  Arrow es una colección de bibliotecas relacionadas al **procesamiento de datos en memoria** que permite construir software de alto desempeño para el procesamiento y transporte de datasets grandes.\n",
    "*  **Procesamiento de datos en memoria** involucra procesamiento de datos en memoria RAM y excluye accesos (lentos) a datos **on-disk**. Cuando los datos son almacenados en disco, los principales problemas consisten en el tamaño de los datos y al costo de las operaciones de **input/output (IO)** de lectura en memoria previos a operar con los datos.\n",
    "*  Los formatos de datos en disco, como **Parquet**, optimizan el throughput de las operaciones I/O mediante la compresión de los datos para hacerlos más pequeños y más rápidos de leer en la memoria.\n",
    "*  Arrow se enfoca en el formato **en memoria**, colocando como objetivo mejorar la eficiencia del CPU mediante estrategias como la localidad de caché y las operaciones vectorizadas.\n",
    "*  Arrow utiliza un modelo de memoria que mejora la eficiencia al compartir datos al eliminar los costos de serialización.\n",
    "*  Arrow utiliza una organización columnar (contigua) de las estructuras de datos en memoria. Esta organización facilita las operaciones vectorizadas del tipo SIMD (single instruction, multiple data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3330f8b8-0875-446f-afa9-f6fd3818dcd3",
   "metadata": {},
   "source": [
    "## Descarga de Arrow\n",
    "* El proyecto Arrow contiene una variedad de bibliotecas para múltiples lenguajes de programación.\n",
    "* <code>pyarrow</code> es la API (Application Programming Interface) de Apache Arrow en Python.\n",
    "\n",
    "### Instalación de <code>pyarrow</code>\n",
    "\n",
    "Podemos usar <code>pip</code> para instalar <code>pyarrow</code> con la siguiente instrucción:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59b6495e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /home/milo/anaconda3/lib/python3.11/site-packages (11.0.0)\r\n",
      "Requirement already satisfied: numpy>=1.16.6 in /home/milo/anaconda3/lib/python3.11/site-packages (from pyarrow) (1.24.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c904cdf",
   "metadata": {},
   "source": [
    "Verificamos si el paquete fue instalado correctamente importándolo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eefc014-a3e5-49eb-ba8c-5eac6474373f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "\n",
    "arr = pa.array([1,2,3,4])\n",
    "arr?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30c76bd-fe47-4553-a159-f70c2fb85c47",
   "metadata": {},
   "source": [
    "## Carga de datos\n",
    "\n",
    "La siguiente figura muestra algunos formatos que son soportados por Arrow:\n",
    "\n",
    "Arrow permite acceder a archivos en distintos sistemas de archivos. La siguiente figura presenta algunas implementaciones a sistemas de archivos:\n",
    "\n",
    "<img src=\"images/arrow_files_format.png\" alt=\"Drawing\" style=\"width: 750px;\"/> \n",
    "\n",
    "\n",
    "Haremos uso de la implementación para el acceso a archivos del sistema de archivos local\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16fdc3cb-ba7d-44e5-b7b0-e3ff54694528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/milo/Documents/mide/diplomado_2024/diplomado_ciencia_datos_mide/'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyarrow import fs\n",
    "\n",
    "local = fs.LocalFileSystem() # create local file system instance\n",
    "f, p = fs.FileSystem.from_uri('file:///home/milo/Documents/mide/diplomado_2024/diplomado_ciencia_datos_mide/')\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843a8031-33c1-486b-bd59-24ba4c6d1d49",
   "metadata": {},
   "source": [
    "### Carga de archivos CSV en <code>pyarrow</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e66a14d-5e74-4cfa-ba22-d5fc01da47ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YEAR: int64\n",
       "MONTH: int64\n",
       "DAY: int64\n",
       "DAY_OF_WEEK: int64\n",
       "AIRLINE: string\n",
       "FLIGHT_NUMBER: int64\n",
       "TAIL_NUMBER: string\n",
       "ORIGIN_AIRPORT: string\n",
       "DESTINATION_AIRPORT: string\n",
       "SCHEDULED_DEPARTURE: int64\n",
       "DEPARTURE_TIME: int64\n",
       "DEPARTURE_DELAY: int64\n",
       "TAXI_OUT: int64\n",
       "WHEELS_OFF: int64\n",
       "SCHEDULED_TIME: int64\n",
       "ELAPSED_TIME: int64\n",
       "AIR_TIME: int64\n",
       "DISTANCE: int64\n",
       "WHEELS_ON: int64\n",
       "TAXI_IN: int64\n",
       "SCHEDULED_ARRIVAL: int64\n",
       "ARRIVAL_TIME: int64\n",
       "ARRIVAL_DELAY: int64\n",
       "DIVERTED: int64\n",
       "CANCELLED: int64\n",
       "CANCELLATION_REASON: string\n",
       "AIR_SYSTEM_DELAY: int64\n",
       "SECURITY_DELAY: int64\n",
       "AIRLINE_DELAY: int64\n",
       "LATE_AIRCRAFT_DELAY: int64\n",
       "WEATHER_DELAY: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.csv\n",
    "\n",
    "table = pa.csv.read_csv('../datos/flights.csv')\n",
    "table.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea25f408-c775-4f83-9821-1515372a36e0",
   "metadata": {},
   "source": [
    "La lectura de un archivo CSV regresa un objeto del tipo <code>pyarrow.Table</code> que contiene una lista de objetos <code>pyarrow.lib.ChunkedArray</code>. \n",
    "\n",
    "Cuando se está leyendo el archivo CSV se puede paralelizar la carga de datos al leer grupos de filas de forma paralela y posteriormente integrar los chunks de las columnas. El proceso se muestra en la siguiente figura:\n",
    "\n",
    "<img src=\"images/arrow_files_format.png\" alt=\"Drawing\" style=\"width: 750px;\"/> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39789ca-6491-4e31-a8f0-dcaf910540d4",
   "metadata": {},
   "source": [
    "## Integración entre Arrow y Pandas\n",
    "\n",
    "El DataFrame de Pandas es equivalente a una Tabla de Arrow. En ambos casos, representan un grupo de columnas con nombre que tienen la misma longitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7914af01-d988-4f96-9343-025a74b7e0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\"a\": [1,2,3]})\n",
    "\n",
    "table = pa.Table.from_pandas(df) # convert to arrow\n",
    "\n",
    "df_new = table.to_pandas() # convert back to pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be73ee6-16cd-40b0-96ed-f376344167d9",
   "metadata": {},
   "source": [
    "Existen opciones para controlar las conversiones entre Pandas y Arrow, como si usar threads, administrar el uso de memoria o los tipos de datos. Los objetos de Pandas tienen índices que puede contener etiquetas de fila para los datos en lugar de simplemente usar un índice de fila basado en enteros. Cuando se realiza la conversión de un DataFrame a Table, las funciones <code>from_pandas</code> tienen una opción llamada <code>preserve_index</code> que se usa para controlar si se almacenan los datos del índice y cómo almacenarlos.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
